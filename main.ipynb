{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f59f9892-29bf-4af3-983e-0e34084b1174",
      "metadata": {
        "id": "f59f9892-29bf-4af3-983e-0e34084b1174"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "1e976f4b",
      "metadata": {},
      "source": [
        "## About Data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "8bcf47a4",
      "metadata": {},
      "source": [
        "Twitter has become an important communication channel in times of emergency.\n",
        "The ubiquitousness of smartphones enables people to announce an emergency they’re observing in real-time. Because of this, more agencies are interested in programatically monitoring Twitter (i.e. disaster relief organizations and news agencies).\n",
        "\n",
        "But, it’s not always clear whether a person’s words are actually announcing a disaster. Take this example:\n",
        "![image.png](assets/tweet_screenshot.png)\n",
        "\n",
        "The author explicitly uses the word “ABLAZE” but means it metaphorically. This is clear to a human right away, especially with the visual aid. But it’s less clear to a machine.\n",
        "\n",
        "-------\n",
        "Columns: \n",
        "\n",
        "id - a unique identifier for each tweet\n",
        "\n",
        "text - the text of the tweet\n",
        "\n",
        "location - the location the tweet was sent from (may be blank)\n",
        "\n",
        "keyword - a particular keyword from the tweet (may be blank)\n",
        "\n",
        "target - in train.csv only, this denotes whether a tweet is about a real disaster (1) or not (0)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "7cb3c716",
      "metadata": {},
      "source": [
        "## Data Prepration"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "4090f26d",
      "metadata": {},
      "source": [
        "### Reading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c993f2ad",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(r'data\\train.csv')\n",
        "test = pd.read_csv(r'data\\test.csv')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "2c29298f",
      "metadata": {},
      "source": [
        "### Investigating the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "cb2d2f63-ec4c-472f-8c43-7437bb0c02c6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cb2d2f63-ec4c-472f-8c43-7437bb0c02c6",
        "outputId": "deafc6dd-14ee-4ecf-85b6-548a64443809"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "____________shape_____________\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7608</th>\n",
              "      <td>10869</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7609</th>\n",
              "      <td>10870</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7610</th>\n",
              "      <td>10871</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7611</th>\n",
              "      <td>10872</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Police investigating after an e-bike collided ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7612</th>\n",
              "      <td>10873</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7613 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id keyword location  \\\n",
              "0         1     NaN      NaN   \n",
              "1         4     NaN      NaN   \n",
              "2         5     NaN      NaN   \n",
              "3         6     NaN      NaN   \n",
              "4         7     NaN      NaN   \n",
              "...     ...     ...      ...   \n",
              "7608  10869     NaN      NaN   \n",
              "7609  10870     NaN      NaN   \n",
              "7610  10871     NaN      NaN   \n",
              "7611  10872     NaN      NaN   \n",
              "7612  10873     NaN      NaN   \n",
              "\n",
              "                                                   text  target  \n",
              "0     Our Deeds are the Reason of this #earthquake M...       1  \n",
              "1                Forest fire near La Ronge Sask. Canada       1  \n",
              "2     All residents asked to 'shelter in place' are ...       1  \n",
              "3     13,000 people receive #wildfires evacuation or...       1  \n",
              "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
              "...                                                 ...     ...  \n",
              "7608  Two giant cranes holding a bridge collapse int...       1  \n",
              "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
              "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
              "7611  Police investigating after an e-bike collided ...       1  \n",
              "7612  The Latest: More Homes Razed by Northern Calif...       1  \n",
              "\n",
              "[7613 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_____________head_____________\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_dbd4f_row0_col0, #T_dbd4f_row0_col4, #T_dbd4f_row1_col4, #T_dbd4f_row2_col4, #T_dbd4f_row3_col4, #T_dbd4f_row4_col4 {\n",
              "  background-color: #f7fbff;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_dbd4f_row1_col0 {\n",
              "  background-color: #6aaed6;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_dbd4f_row2_col0 {\n",
              "  background-color: #3787c0;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_dbd4f_row3_col0 {\n",
              "  background-color: #105ba4;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_dbd4f_row4_col0 {\n",
              "  background-color: #08306b;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_dbd4f\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_dbd4f_level0_col0\" class=\"col_heading level0 col0\" >id</th>\n",
              "      <th id=\"T_dbd4f_level0_col1\" class=\"col_heading level0 col1\" >keyword</th>\n",
              "      <th id=\"T_dbd4f_level0_col2\" class=\"col_heading level0 col2\" >location</th>\n",
              "      <th id=\"T_dbd4f_level0_col3\" class=\"col_heading level0 col3\" >text</th>\n",
              "      <th id=\"T_dbd4f_level0_col4\" class=\"col_heading level0 col4\" >target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_dbd4f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_dbd4f_row0_col0\" class=\"data row0 col0\" >1</td>\n",
              "      <td id=\"T_dbd4f_row0_col1\" class=\"data row0 col1\" >nan</td>\n",
              "      <td id=\"T_dbd4f_row0_col2\" class=\"data row0 col2\" >nan</td>\n",
              "      <td id=\"T_dbd4f_row0_col3\" class=\"data row0 col3\" >Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all</td>\n",
              "      <td id=\"T_dbd4f_row0_col4\" class=\"data row0 col4\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_dbd4f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_dbd4f_row1_col0\" class=\"data row1 col0\" >4</td>\n",
              "      <td id=\"T_dbd4f_row1_col1\" class=\"data row1 col1\" >nan</td>\n",
              "      <td id=\"T_dbd4f_row1_col2\" class=\"data row1 col2\" >nan</td>\n",
              "      <td id=\"T_dbd4f_row1_col3\" class=\"data row1 col3\" >Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td id=\"T_dbd4f_row1_col4\" class=\"data row1 col4\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_dbd4f_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_dbd4f_row2_col0\" class=\"data row2 col0\" >5</td>\n",
              "      <td id=\"T_dbd4f_row2_col1\" class=\"data row2 col1\" >nan</td>\n",
              "      <td id=\"T_dbd4f_row2_col2\" class=\"data row2 col2\" >nan</td>\n",
              "      <td id=\"T_dbd4f_row2_col3\" class=\"data row2 col3\" >All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected</td>\n",
              "      <td id=\"T_dbd4f_row2_col4\" class=\"data row2 col4\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_dbd4f_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_dbd4f_row3_col0\" class=\"data row3 col0\" >6</td>\n",
              "      <td id=\"T_dbd4f_row3_col1\" class=\"data row3 col1\" >nan</td>\n",
              "      <td id=\"T_dbd4f_row3_col2\" class=\"data row3 col2\" >nan</td>\n",
              "      <td id=\"T_dbd4f_row3_col3\" class=\"data row3 col3\" >13,000 people receive #wildfires evacuation orders in California </td>\n",
              "      <td id=\"T_dbd4f_row3_col4\" class=\"data row3 col4\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_dbd4f_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_dbd4f_row4_col0\" class=\"data row4 col0\" >7</td>\n",
              "      <td id=\"T_dbd4f_row4_col1\" class=\"data row4 col1\" >nan</td>\n",
              "      <td id=\"T_dbd4f_row4_col2\" class=\"data row4 col2\" >nan</td>\n",
              "      <td id=\"T_dbd4f_row4_col3\" class=\"data row4 col3\" >Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school </td>\n",
              "      <td id=\"T_dbd4f_row4_col4\" class=\"data row4 col4\" >1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x1faa8d37be0>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_____________tail_____________\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_5ef63_row0_col0, #T_5ef63_row0_col4, #T_5ef63_row1_col4, #T_5ef63_row2_col4, #T_5ef63_row3_col4, #T_5ef63_row4_col4 {\n",
              "  background-color: #f7fbff;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_5ef63_row1_col0 {\n",
              "  background-color: #c6dbef;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_5ef63_row2_col0 {\n",
              "  background-color: #6aaed6;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_5ef63_row3_col0 {\n",
              "  background-color: #2070b4;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_5ef63_row4_col0 {\n",
              "  background-color: #08306b;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_5ef63\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_5ef63_level0_col0\" class=\"col_heading level0 col0\" >id</th>\n",
              "      <th id=\"T_5ef63_level0_col1\" class=\"col_heading level0 col1\" >keyword</th>\n",
              "      <th id=\"T_5ef63_level0_col2\" class=\"col_heading level0 col2\" >location</th>\n",
              "      <th id=\"T_5ef63_level0_col3\" class=\"col_heading level0 col3\" >text</th>\n",
              "      <th id=\"T_5ef63_level0_col4\" class=\"col_heading level0 col4\" >target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_5ef63_level0_row0\" class=\"row_heading level0 row0\" >7608</th>\n",
              "      <td id=\"T_5ef63_row0_col0\" class=\"data row0 col0\" >10869</td>\n",
              "      <td id=\"T_5ef63_row0_col1\" class=\"data row0 col1\" >nan</td>\n",
              "      <td id=\"T_5ef63_row0_col2\" class=\"data row0 col2\" >nan</td>\n",
              "      <td id=\"T_5ef63_row0_col3\" class=\"data row0 col3\" >Two giant cranes holding a bridge collapse into nearby homes http://t.co/STfMbbZFB5</td>\n",
              "      <td id=\"T_5ef63_row0_col4\" class=\"data row0 col4\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5ef63_level0_row1\" class=\"row_heading level0 row1\" >7609</th>\n",
              "      <td id=\"T_5ef63_row1_col0\" class=\"data row1 col0\" >10870</td>\n",
              "      <td id=\"T_5ef63_row1_col1\" class=\"data row1 col1\" >nan</td>\n",
              "      <td id=\"T_5ef63_row1_col2\" class=\"data row1 col2\" >nan</td>\n",
              "      <td id=\"T_5ef63_row1_col3\" class=\"data row1 col3\" >@aria_ahrary @TheTawniest The out of control wild fires in California even in the Northern part of the state. Very troubling.</td>\n",
              "      <td id=\"T_5ef63_row1_col4\" class=\"data row1 col4\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5ef63_level0_row2\" class=\"row_heading level0 row2\" >7610</th>\n",
              "      <td id=\"T_5ef63_row2_col0\" class=\"data row2 col0\" >10871</td>\n",
              "      <td id=\"T_5ef63_row2_col1\" class=\"data row2 col1\" >nan</td>\n",
              "      <td id=\"T_5ef63_row2_col2\" class=\"data row2 col2\" >nan</td>\n",
              "      <td id=\"T_5ef63_row2_col3\" class=\"data row2 col3\" >M1.94 [01:04 UTC]?5km S of Volcano Hawaii. http://t.co/zDtoyd8EbJ</td>\n",
              "      <td id=\"T_5ef63_row2_col4\" class=\"data row2 col4\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5ef63_level0_row3\" class=\"row_heading level0 row3\" >7611</th>\n",
              "      <td id=\"T_5ef63_row3_col0\" class=\"data row3 col0\" >10872</td>\n",
              "      <td id=\"T_5ef63_row3_col1\" class=\"data row3 col1\" >nan</td>\n",
              "      <td id=\"T_5ef63_row3_col2\" class=\"data row3 col2\" >nan</td>\n",
              "      <td id=\"T_5ef63_row3_col3\" class=\"data row3 col3\" >Police investigating after an e-bike collided with a car in Little Portugal. E-bike rider suffered serious non-life threatening injuries.</td>\n",
              "      <td id=\"T_5ef63_row3_col4\" class=\"data row3 col4\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5ef63_level0_row4\" class=\"row_heading level0 row4\" >7612</th>\n",
              "      <td id=\"T_5ef63_row4_col0\" class=\"data row4 col0\" >10873</td>\n",
              "      <td id=\"T_5ef63_row4_col1\" class=\"data row4 col1\" >nan</td>\n",
              "      <td id=\"T_5ef63_row4_col2\" class=\"data row4 col2\" >nan</td>\n",
              "      <td id=\"T_5ef63_row4_col3\" class=\"data row4 col3\" >The Latest: More Homes Razed by Northern California Wildfire - ABC News http://t.co/YmY4rSkQ3d</td>\n",
              "      <td id=\"T_5ef63_row4_col4\" class=\"data row4 col4\" >1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x1faa96370a0>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_____________info_____________\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7613 entries, 0 to 7612\n",
            "Data columns (total 5 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   id        7613 non-null   int64 \n",
            " 1   keyword   7552 non-null   object\n",
            " 2   location  5080 non-null   object\n",
            " 3   text      7613 non-null   object\n",
            " 4   target    7613 non-null   int64 \n",
            "dtypes: int64(2), object(3)\n",
            "memory usage: 297.5+ KB\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_____describe_continuous______\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_29aef_row0_col0, #T_29aef_row1_col0, #T_29aef_row1_col1, #T_29aef_row1_col2, #T_29aef_row1_col3, #T_29aef_row1_col4, #T_29aef_row1_col5, #T_29aef_row1_col6, #T_29aef_row1_col7 {\n",
              "  background-color: #f7fbff;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_29aef_row0_col1, #T_29aef_row0_col2, #T_29aef_row0_col3, #T_29aef_row0_col4, #T_29aef_row0_col5, #T_29aef_row0_col6, #T_29aef_row0_col7 {\n",
              "  background-color: #08306b;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_29aef\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_29aef_level0_col0\" class=\"col_heading level0 col0\" >count</th>\n",
              "      <th id=\"T_29aef_level0_col1\" class=\"col_heading level0 col1\" >mean</th>\n",
              "      <th id=\"T_29aef_level0_col2\" class=\"col_heading level0 col2\" >std</th>\n",
              "      <th id=\"T_29aef_level0_col3\" class=\"col_heading level0 col3\" >min</th>\n",
              "      <th id=\"T_29aef_level0_col4\" class=\"col_heading level0 col4\" >25%</th>\n",
              "      <th id=\"T_29aef_level0_col5\" class=\"col_heading level0 col5\" >50%</th>\n",
              "      <th id=\"T_29aef_level0_col6\" class=\"col_heading level0 col6\" >75%</th>\n",
              "      <th id=\"T_29aef_level0_col7\" class=\"col_heading level0 col7\" >max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_29aef_level0_row0\" class=\"row_heading level0 row0\" >id</th>\n",
              "      <td id=\"T_29aef_row0_col0\" class=\"data row0 col0\" >7613.000000</td>\n",
              "      <td id=\"T_29aef_row0_col1\" class=\"data row0 col1\" >5441.934848</td>\n",
              "      <td id=\"T_29aef_row0_col2\" class=\"data row0 col2\" >3137.116090</td>\n",
              "      <td id=\"T_29aef_row0_col3\" class=\"data row0 col3\" >1.000000</td>\n",
              "      <td id=\"T_29aef_row0_col4\" class=\"data row0 col4\" >2734.000000</td>\n",
              "      <td id=\"T_29aef_row0_col5\" class=\"data row0 col5\" >5408.000000</td>\n",
              "      <td id=\"T_29aef_row0_col6\" class=\"data row0 col6\" >8146.000000</td>\n",
              "      <td id=\"T_29aef_row0_col7\" class=\"data row0 col7\" >10873.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_29aef_level0_row1\" class=\"row_heading level0 row1\" >target</th>\n",
              "      <td id=\"T_29aef_row1_col0\" class=\"data row1 col0\" >7613.000000</td>\n",
              "      <td id=\"T_29aef_row1_col1\" class=\"data row1 col1\" >0.429660</td>\n",
              "      <td id=\"T_29aef_row1_col2\" class=\"data row1 col2\" >0.495060</td>\n",
              "      <td id=\"T_29aef_row1_col3\" class=\"data row1 col3\" >0.000000</td>\n",
              "      <td id=\"T_29aef_row1_col4\" class=\"data row1 col4\" >0.000000</td>\n",
              "      <td id=\"T_29aef_row1_col5\" class=\"data row1 col5\" >0.000000</td>\n",
              "      <td id=\"T_29aef_row1_col6\" class=\"data row1 col6\" >1.000000</td>\n",
              "      <td id=\"T_29aef_row1_col7\" class=\"data row1 col7\" >1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x1faa8d7edc0>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_____describe_categorical_____\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_9f63c\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_9f63c_level0_col0\" class=\"col_heading level0 col0\" >count</th>\n",
              "      <th id=\"T_9f63c_level0_col1\" class=\"col_heading level0 col1\" >unique</th>\n",
              "      <th id=\"T_9f63c_level0_col2\" class=\"col_heading level0 col2\" >top</th>\n",
              "      <th id=\"T_9f63c_level0_col3\" class=\"col_heading level0 col3\" >freq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_9f63c_level0_row0\" class=\"row_heading level0 row0\" >keyword</th>\n",
              "      <td id=\"T_9f63c_row0_col0\" class=\"data row0 col0\" >7552</td>\n",
              "      <td id=\"T_9f63c_row0_col1\" class=\"data row0 col1\" >221</td>\n",
              "      <td id=\"T_9f63c_row0_col2\" class=\"data row0 col2\" >fatalities</td>\n",
              "      <td id=\"T_9f63c_row0_col3\" class=\"data row0 col3\" >45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9f63c_level0_row1\" class=\"row_heading level0 row1\" >location</th>\n",
              "      <td id=\"T_9f63c_row1_col0\" class=\"data row1 col0\" >5080</td>\n",
              "      <td id=\"T_9f63c_row1_col1\" class=\"data row1 col1\" >3341</td>\n",
              "      <td id=\"T_9f63c_row1_col2\" class=\"data row1 col2\" >USA</td>\n",
              "      <td id=\"T_9f63c_row1_col3\" class=\"data row1 col3\" >104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_9f63c_level0_row2\" class=\"row_heading level0 row2\" >text</th>\n",
              "      <td id=\"T_9f63c_row2_col0\" class=\"data row2 col0\" >7613</td>\n",
              "      <td id=\"T_9f63c_row2_col1\" class=\"data row2 col1\" >7503</td>\n",
              "      <td id=\"T_9f63c_row2_col2\" class=\"data row2 col2\" >11-Year-Old Boy Charged With Manslaughter of Toddler: Report: An 11-year-old boy has been charged with manslaughter over the fatal sh...</td>\n",
              "      <td id=\"T_9f63c_row2_col3\" class=\"data row2 col3\" >10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x1faa8d7edc0>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_____null_values_percent______\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "location    33.272035\n",
              "keyword      0.801261\n",
              "id           0.000000\n",
              "text         0.000000\n",
              "target       0.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def background_color(value):\n",
        "    if isinstance(value, str):\n",
        "        return 'background-color: #a6c0ed'\n",
        "    return ''\n",
        "\n",
        "def show_df(df_train):\n",
        "    print('shape'.center(30,'_'))\n",
        "    display(df_train)\n",
        "\n",
        "    print('head'.center(30,'_'))\n",
        "    display(df_train.head().style.background_gradient(cmap='Blues'))\n",
        "\n",
        "    print('tail'.center(30,'_'))\n",
        "    display(df_train.tail().style.background_gradient(cmap='Blues'))\n",
        "\n",
        "    print('info'.center(30,'_')+'\\n')\n",
        "    display(df_train.info())\n",
        "\n",
        "    print('describe_continuous'.center(30,'_'))\n",
        "    display(df_train.describe().T.style.background_gradient(cmap = 'Blues'))\n",
        "\n",
        "    print('describe_categorical'.center(30,'_'))\n",
        "    display(df_train.describe(include='object').T.style.background_gradient(cmap='Blues'))\n",
        "\n",
        "    print('null_values_percent'.center(30,'_'))\n",
        "    display((df_train.isna().sum() / len(df_train) * 100).sort_values(ascending=False))\n",
        "show_df(df_train)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "7a8e9dce",
      "metadata": {},
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "9e2c341f",
      "metadata": {},
      "source": [
        "#### Removing URL's from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a4531edd-38c5-442d-853e-9e19ea0a7dff",
      "metadata": {
        "id": "a4531edd-38c5-442d-853e-9e19ea0a7dff"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "def remove_URL(text):\n",
        "    url = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
        "    return url.sub(r\"\", text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b4f07c0e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text Before:\n",
            " We always try to bring the heavy. #metal #RT http://t.co/YAo1e0xngw\n",
            "Text After:\n",
            " We always try to bring the heavy. #metal #RT \n"
          ]
        }
      ],
      "source": [
        "print(\"Text Before:\\n\", df_train.text[32])\n",
        "print(\"Text After:\\n\",remove_URL(df_train.text[32]))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "154335b4",
      "metadata": {},
      "source": [
        "#### Removing punctuations from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "60d5f3f7-e72a-4a8a-ae11-a68a35c09fa9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "60d5f3f7-e72a-4a8a-ae11-a68a35c09fa9",
        "outputId": "8d3c2aed-bbf7-472a-a373-c3115de65e79"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def remove_punct(text):\n",
        "    translator = str.maketrans(\"\", \"\", string.punctuation)\n",
        "    return text.translate(translator)\n",
        "\n",
        "string.punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3f04f86b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text Before:\n",
            " All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected\n",
            "Text After:\n",
            " All residents asked to shelter in place are being notified by officers No other evacuation or shelter in place orders are expected\n"
          ]
        }
      ],
      "source": [
        "print(\"Text Before:\\n\", df_train.text[2])\n",
        "print(\"Text After:\\n\",remove_punct(df_train.text[2]))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "13b03b0c",
      "metadata": {},
      "source": [
        "#### Removing stop words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "012fc189-ea1d-4b28-9c1b-08b0a0b49df1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "012fc189-ea1d-4b28-9c1b-08b0a0b49df1",
        "outputId": "d7988644-1727-4721-9499-4e3701ee43d5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
            "[nltk_data]     getaddrinfo failed>\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2dba0421",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Stop words example\n",
        "stopwords.words(\"english\")[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "74ccbbf9-0991-4b83-9be8-84fb5394a817",
      "metadata": {
        "id": "74ccbbf9-0991-4b83-9be8-84fb5394a817"
      },
      "outputs": [],
      "source": [
        "def remove_stopwords(text):\n",
        "    stop = set(stopwords.words(\"english\"))\n",
        "    \n",
        "    filtered_words = [word.lower() for word in text.split() if word.lower() not in stop]\n",
        "    return \" \".join(filtered_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d70ce792",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text Before:\n",
            " All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected\n",
            "Text After:\n",
            " residents asked 'shelter place' notified officers. evacuation shelter place orders expected\n"
          ]
        }
      ],
      "source": [
        "print(\"Text Before:\\n\", df_train.text[2])\n",
        "print(\"Text After:\\n\",remove_stopwords(df_train.text[2]))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "7814d168-ca43-4c1e-97f2-3267d051296a",
      "metadata": {
        "id": "7814d168-ca43-4c1e-97f2-3267d051296a"
      },
      "source": [
        "#### Now let's apply our cleaning methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "3753649e-abde-481f-865d-f7c528c6a88c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3753649e-abde-481f-865d-f7c528c6a88c",
        "outputId": "4d336960-2155-4b4f-f282-b911342b1266"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0            deeds reason earthquake may allah forgive us\n",
              "1                   forest fire near la ronge sask canada\n",
              "2       residents asked shelter place notified officer...\n",
              "3       13000 people receive wildfires evacuation orde...\n",
              "4       got sent photo ruby alaska smoke wildfires pou...\n",
              "                              ...                        \n",
              "7608    two giant cranes holding bridge collapse nearb...\n",
              "7609    ariaahrary thetawniest control wild fires cali...\n",
              "7610                      m194 0104 utc5km volcano hawaii\n",
              "7611    police investigating ebike collided car little...\n",
              "7612    latest homes razed northern california wildfir...\n",
              "Name: text, Length: 7613, dtype: object"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train[\"text\"] = df_train.text.map(remove_URL) # map(lambda x: remove_URL(x))\n",
        "df_train[\"text\"] = df_train.text.map(remove_punct)\n",
        "df_train[\"text\"] = df_train.text.map(remove_stopwords)\n",
        "df_train[\"text\"]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "02628923",
      "metadata": {},
      "source": [
        "-------------"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "824eb9bb",
      "metadata": {},
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "3cb98998",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Error loading punkt: <urlopen error [Errno 11001]\n",
            "[nltk_data]     getaddrinfo failed>\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "8373c67b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    [deeds, reason, earthquake, may, allah, forgiv...\n",
              "1        [forest, fire, near, la, ronge, sask, canada]\n",
              "2    [residents, asked, shelter, place, notified, o...\n",
              "3    [13000, people, receive, wildfires, evacuation...\n",
              "4    [got, sent, photo, ruby, alaska, smoke, wildfi...\n",
              "Name: text, dtype: object"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train[\"text\"] = df_train.text.map(nltk.tokenize.word_tokenize)\n",
        "df_train.text.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "b108fc86",
      "metadata": {},
      "source": [
        "### Lemmatizing the tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "ee4657d8",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Error loading wordnet: <urlopen error [Errno 11001]\n",
            "[nltk_data]     getaddrinfo failed>\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "8f29e51a",
      "metadata": {},
      "outputs": [],
      "source": [
        "def Lemmatize(sentence_tokens):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    result_sentence = []\n",
        "    for token in sentence_tokens:\n",
        "        result_sentence.append(lemmatizer.lemmatize(token))\n",
        "    return result_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "fe49af82",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    [deed, reason, earthquake, may, allah, forgive...\n",
              "1        [forest, fire, near, la, ronge, sask, canada]\n",
              "2    [resident, asked, shelter, place, notified, of...\n",
              "3    [13000, people, receive, wildfire, evacuation,...\n",
              "4    [got, sent, photo, ruby, alaska, smoke, wildfi...\n",
              "Name: text, dtype: object"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train[\"text\"] = df_train.text.map(Lemmatize)\n",
        "df_train.text.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "78b5e877",
      "metadata": {},
      "source": [
        "## Calculate Probabilty with N-grams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "f4e69eaa",
      "metadata": {},
      "outputs": [],
      "source": [
        "from nltk.util import ngrams"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "2b798df0",
      "metadata": {},
      "source": [
        "#### Calculate tokens frequencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "0bd4fbf0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Flatten the token as putting them all in single list\n",
        "def flatten_tokens(df):\n",
        "    tokens = [token for item in df for token in item]      \n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "d4d347a1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('fire', 350),\n",
              " ('like', 347),\n",
              " ('im', 299),\n",
              " ('amp', 298),\n",
              " ('get', 255),\n",
              " ('u', 246),\n",
              " ('new', 224),\n",
              " ('via', 220),\n",
              " ('one', 205),\n",
              " ('people', 199)]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokens = flatten_tokens(df_train.text)\n",
        "tokens_fd = nltk.FreqDist(tokens)\n",
        "tokens_fd.most_common(10)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "edce08c8",
      "metadata": {},
      "source": [
        "#### Get Bigrams and calculate their frequencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "5881d8db",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    [(deed, reason), (reason, earthquake), (earthq...\n",
              "1    [(forest, fire), (fire, near), (near, la), (la...\n",
              "2    [(resident, asked), (asked, shelter), (shelter...\n",
              "3    [(13000, people), (people, receive), (receive,...\n",
              "4    [(got, sent), (sent, photo), (photo, ruby), (r...\n",
              "Name: text, dtype: object"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bigrams = df_train.text.apply(lambda x:list(ngrams(x, 2)))\n",
        "bigrams[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "0f018111",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Flatten the bigrams as putting them all in single list\n",
        "def flatten_bigrams(df):\n",
        "    bigrams = [bigram for item in df for bigram in item]\n",
        "    return bigrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "b86fd4da",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "64158"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(flatten_bigrams(bigrams))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "3d17fcfa",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(('suicide', 'bomber'), 60),\n",
              " (('burning', 'building'), 58),\n",
              " (('look', 'like'), 49),\n",
              " (('body', 'bag'), 48),\n",
              " (('gon', 'na'), 43),\n",
              " (('youtube', 'video'), 43),\n",
              " (('liked', 'youtube'), 42),\n",
              " (('northern', 'california'), 41),\n",
              " (('cross', 'body'), 39),\n",
              " (('oil', 'spill'), 39)]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fd_bi = nltk.FreqDist(get_all_bigrams(bigrams))\n",
        "fd_bi.most_common(10)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "cf0cb890",
      "metadata": {},
      "source": [
        "### Estimating the probabiltiy of a word sequence\n",
        "P(x1, x2, ..., xn) = P(x1)P(x2|x1)...P(xn|x1,...xn-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "e4d7c623",
      "metadata": {},
      "outputs": [],
      "source": [
        "def prob_calc(sentence):\n",
        "    probs = [tokens_fd.freq(sentence[0][0])] # prob of first token\n",
        "    print(f\"P({sentence[0][0]}) = {probs[0]:.3}\")\n",
        "    for bigram in sentence:\n",
        "        prob = fd_bi.freq(bigram) / tokens_fd.freq(bigram[0])\n",
        "        probs.append(prob)\n",
        "        print(f\"P({bigram[0]} | {bigram[1]}) = {prob:.3}\")\n",
        "    print(\"=\"*40)\n",
        "    \n",
        "    res = probs[0] \n",
        "    sen = \" \".join([word[0] for word in sentence])\n",
        "    print(f\"P({sen}) = ({probs[0]:.4})\",end=\"\")\n",
        "    for prob in probs[1:]:\n",
        "        res *= prob\n",
        "        print(f\" * ({prob:.4})\", end= \"\")\n",
        "    print(f\" = {res:.2}\")\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "5cd4c2c3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "P(deed) = 2.79e-05\n",
            "P(deed | reason) = 0.559\n",
            "P(reason | earthquake) = 0.0361\n",
            "P(earthquake | may) = 0.0211\n",
            "P(may | allah) = 0.0381\n",
            "P(allah | forgive) = 0.124\n",
            "P(forgive | u) = 0.559\n",
            "========================================\n",
            "P(deed reason earthquake may allah forgive) = (2.787e-05) * (0.5593) * (0.03609) * (0.02111) * (0.03814) * (0.1243) * (0.5593) = 3.1e-11\n",
            "\n",
            "\n",
            "P(forest) = 0.00092\n",
            "P(forest | fire) = 0.475\n",
            "P(fire | near) = 0.0128\n",
            "P(near | la) = 0.0207\n",
            "P(la | ronge) = 0.04\n",
            "P(ronge | sask) = 1.12\n",
            "P(sask | canada) = 1.12\n",
            "========================================\n",
            "P(forest fire near la ronge sask) = (0.0009196) * (0.4746) * (0.01278) * (0.02072) * (0.03995) * (1.119) * (1.119) = 5.8e-09\n",
            "\n",
            "\n",
            "P(resident) = 0.000111\n",
            "P(resident | asked) = 0.14\n",
            "P(asked | shelter) = 0.124\n",
            "P(shelter | place) = 0.373\n",
            "P(place | notified) = 0.0361\n",
            "P(notified | officer) = 1.12\n",
            "P(officer | evacuation) = 0.0302\n",
            "P(evacuation | shelter) = 0.0215\n",
            "P(shelter | place) = 0.373\n",
            "P(place | order) = 0.0361\n",
            "P(order | expected) = 0.032\n",
            "========================================\n",
            "P(resident asked shelter place notified officer evacuation shelter place order) = (0.0001115) * (0.1398) * (0.1243) * (0.3729) * (0.03609) * (1.119) * (0.03023) * (0.02151) * (0.3729) * (0.03609) * (0.03196) = 8.2e-15\n",
            "\n",
            "\n",
            "P(13000) = 5.57e-05\n",
            "P(13000 | people) = 0.28\n",
            "P(people | receive) = 0.00562\n",
            "P(receive | wildfire) = 0.559\n",
            "P(wildfire | evacuation) = 0.0135\n",
            "P(evacuation | order) = 0.215\n",
            "P(order | california) = 0.032\n",
            "========================================\n",
            "P(13000 people receive wildfire evacuation order) = (5.573e-05) * (0.2797) * (0.005621) * (0.5593) * (0.01348) * (0.2151) * (0.03196) = 4.5e-12\n",
            "\n",
            "\n",
            "P(got) = 0.00171\n",
            "P(got | sent) = 0.00909\n",
            "P(sent | photo) = 0.0861\n",
            "P(photo | ruby) = 0.0172\n",
            "P(ruby | alaska) = 1.12\n",
            "P(alaska | smoke) = 0.16\n",
            "P(smoke | wildfire) = 0.0228\n",
            "P(wildfire | pours) = 0.0135\n",
            "P(pours | school) = 1.12\n",
            "========================================\n",
            "P(got sent photo ruby alaska smoke wildfire pours) = (0.001714) * (0.009095) * (0.08605) * (0.01721) * (1.119) * (0.1598) * (0.02283) * (0.01348) * (1.119) = 1.4e-12\n",
            "\n",
            "\n",
            "P(rockyfire) = 5.57e-05\n",
            "P(rockyfire | update) = 0.28\n",
            "P(update | california) = 0.0233\n",
            "P(california | hwy) = 0.00925\n",
            "P(hwy | 20) = 0.249\n",
            "P(20 | closed) = 0.04\n",
            "P(closed | direction) = 0.0559\n",
            "P(direction | due) = 0.0746\n",
            "P(due | lake) = 0.0361\n",
            "P(lake | county) = 0.0699\n",
            "P(county | fire) = 0.0589\n",
            "P(fire | cafire) = 0.0032\n",
            "P(cafire | wildfire) = 0.559\n",
            "========================================\n",
            "P(rockyfire update california hwy 20 closed direction due lake county fire cafire) = (5.573e-05) * (0.2797) * (0.02331) * (0.009245) * (0.2486) * (0.03995) * (0.05593) * (0.07458) * (0.03609) * (0.06992) * (0.05888) * (0.003196) * (0.5593) = 3.7e-20\n",
            "\n",
            "\n",
            "P(flood) = 0.00157\n",
            "P(flood | disaster) = 0.0297\n",
            "P(disaster | heavy) = 0.00722\n",
            "P(heavy | rain) = 0.503\n",
            "P(rain | cause) = 0.0215\n",
            "P(cause | flash) = 0.0183\n",
            "P(flash | flooding) = 0.213\n",
            "P(flooding | street) = 0.0224\n",
            "P(street | manitou) = 0.035\n",
            "P(manitou | colorado) = 1.12\n",
            "P(colorado | spring) = 0.0699\n",
            "P(spring | area) = 0.0621\n",
            "========================================\n",
            "P(flood disaster heavy rain cause flash flooding street manitou colorado spring) = (0.001574) * (0.0297) * (0.007217) * (0.5034) * (0.02151) * (0.01834) * (0.2131) * (0.02237) * (0.03496) * (1.119) * (0.06992) * (0.06215) = 5.4e-17\n",
            "\n",
            "\n",
            "P(im) = 0.00417\n",
            "P(im | top) = 0.00374\n",
            "P(top | hill) = 0.02\n",
            "P(hill | see) = 0.0932\n",
            "P(see | fire) = 0.03\n",
            "P(fire | wood) = 0.0032\n",
            "========================================\n",
            "P(im top hill see fire) = (0.004166) * (0.003741) * (0.01998) * (0.09322) * (0.02996) * (0.003196) = 2.8e-12\n",
            "\n",
            "\n",
            "P(there) = 0.000627\n",
            "P(there | emergency) = 0.0249\n",
            "P(emergency | evacuation) = 0.0142\n",
            "P(evacuation | happening) = 0.0215\n",
            "P(happening | building) = 0.0861\n",
            "P(building | across) = 0.00799\n",
            "P(across | street) = 0.0559\n",
            "========================================\n",
            "P(there emergency evacuation happening building across) = (0.000627) * (0.02486) * (0.01416) * (0.02151) * (0.08605) * (0.00799) * (0.05593) = 1.8e-13\n",
            "\n",
            "\n",
            "P(im) = 0.00417\n",
            "P(im | afraid) = 0.00374\n",
            "P(afraid | tornado) = 0.224\n",
            "P(tornado | coming) = 0.0294\n",
            "P(coming | area) = 0.0215\n",
            "========================================\n",
            "P(im afraid tornado coming) = (0.004166) * (0.003741) * (0.2237) * (0.02944) * (0.02151) = 2.2e-09\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for bigram in bigrams[0:10]:\n",
        "    prob_calc(bigram)\n",
        "    print(\"\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "1ad7b6933dbeb3066655e7b4b1019487631d0edeeb6c28cdb2f62ca1713ab7c6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
